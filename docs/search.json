[
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks",
    "section": "",
    "text": "Upcoming\nNone at this time.\n\n\nPast\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to keep information ‚Äòfresh‚Äô\n\n\n\n\n\n\nCommunication\n\n\nTechnology\n\n\n\nThe talk will introduce the concept of the ‚Äòage of information‚Äô‚Äîa metric used to assess the freshness of information‚Äîand analyze this metric within a random multi-access system involving numerous devices\n\n\n\n\n\nNov 17, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/2021-11-09_awra_insecticides_water/index.html",
    "href": "talks/2021-11-09_awra_insecticides_water/index.html",
    "title": "Aquatic Risk Assessment: Organophosphate insecticide mixtures in Washington surface waters",
    "section": "",
    "text": "Slides\n\nDetails\nüìÜ November 9, 2021 // 1:30 pm - 1:50 pm PT\nüè® Virtual\nüå† American Water Resources Association (AWRA)\n\n\nAbstract\nEcological risk assessments often do not consider potential additive, synergistic, or antagonistic effects from mixtures of chemicals and instead typically base risk on a single chemical. In the last decade, more tools and models have been developed to consider the interactive effects of chemicals within a mixture when conducting risk assessments. Therefore, this study uses actual environmental concentrations measured in 2018 and 2019 from the Washington State Department of Agriculture‚Äôs Surface Water Monitoring Program. Aquatic risk from exposure was assessed from chlorpyrifos, diazinon, and malathion (as individual chemicals and as binary and ternary mixtures) using the concentration addition model. These pesticides were selected because they have a common mechanism of toxicity, are frequently detected in surface waters in Washington, and were recently evaluated in a biological opinion by the National Marine Fisheries Service.\nAll detected concentrations of chlorpyrifos and malathion, assessed as individual chemicals, exceeded the predicted no effect concentration, indicating potential for adverse effects on aquatic life. Further, risk quotients for all binary and ternary mixtures were greater than one, also indicative of potential for adverse effects on aquatic life. In all samples containing a mixture, the maximum cumulative ratio suggested that a single insecticide contributed &gt;50% of the overall toxicity of each mixture. Based on the individual and mixture risk quotients, chlorpyrifos and malathion were the primary drivers of the toxicity of each mixture.\n\n\nSlides\n\n\nOops! Your browser doesn‚Äôt seem to support embedded PDFs.\n\n\nTry downloading instead.\n\n\n\n\n\n\nCitationBibTeX citation:@online{ryan2021,\n  author = {Ryan, Jadey},\n  title = {Aquatic {Risk} {Assessment:} {Organophosphate} Insecticide\n    Mixtures in {Washington} Surface Waters},\n  date = {2021-11-09},\n  url = {https://ntluong95.github.io/profile/talks/2021-11-09_awra_insecticides_water/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRyan, Jadey. 2021. ‚ÄúAquatic Risk Assessment: Organophosphate\nInsecticide Mixtures in Washington Surface Waters.‚Äù November 9,\n2021. https://ntluong95.github.io/profile/talks/2021-11-09_awra_insecticides_water/."
  },
  {
    "objectID": "projects/amr_trend.html",
    "href": "projects/amr_trend.html",
    "title": "AMR Global Trend",
    "section": "",
    "text": "App  Code\nThe ShinyApp is the supplementary materials for the article:\nAssociation between national policy and trends in antibiotic resistance: an analysis of 73 countries from 2000 to 2023\nPeter S√∏gaard J√∏rgensen1,2,3,, Luong Nguyen Thanh1,3, Ege Pehlivanoglu1, Franziska Klein1,#a, Didier Wernli4, Dusan Jasovsky5,#b, Athena Aktipis6, Rob R. Dunn7, Yrjo Gr√∂hn8, Guillaume Lhermie8,#c, H. Morgan Scott9, Eili Y. Klein10,11\nAffiliations:\n1 Global Economic Dynamics and the Biosphere, The Royal Swedish Academy of Sciences, SE-114 18, Stockholm, Sweden\n2 Stockholm Resilience Centre, Stockholm University, SE-106 91, Stockholm, Sweden\n3 Uppsala Antibiotic Centre and Department of Women‚Äôs and Children‚Äôs Health, Uppsala University, SE-751 05, Uppsala, Sweden\n4 University of Geneva, Global Studies Institute, Transformative Governance Lab, CH-1211 Gen√®ve 4, Switzerland\n5 Uppsala University, ReAct Europe, SE-753 10, Uppsala, Sweden\n6 Arizona State University, Department of Psychology, Tempe, AZ 85281, USA\n7 North Carolina State University, Department of Applied Ecology, Raleigh, NC 27695-7617, USA\n8 Cornell University, College of Veterinary Medicine, Ithaca, NY 14853, USA\n9 Texas A&M University, College Station, TX 77843-4467, USA\n10 One Health Trust, Washington, D.C. 20015, USA\n11 Johns Hopkins School of Medicine, Department of Emergency Medicine, Baltimore, MD 21205, USA\n\n\n\nScreenshot from the App"
  },
  {
    "objectID": "projects/aetranslations.html",
    "href": "projects/aetranslations.html",
    "title": "{aetranslations}",
    "section": "",
    "text": "{pkgdown} site  Code  CRAN \nThis package hosts functions and guidelines for translating Applied Epi courses and resources. This includes courses materials (slides, exercises, tutorials), website (i.e.¬†case studies) and books (i.e.¬†the EpiRhandbook and the Applied Epi Manual). By leveraging AI services like DeepL or OpenAI, {aetranslations} package streamlines the process to make the Applied Epi materials available in multiple languages."
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Uppsala University\n\n\nPhD student Oct 2021 ‚Äì Present\n\nPhD project: Analyzed the degree to which factors driving antimicrobial resistance (AMR) development and spread are addressed by AMR-specific policies and interventions versus broader societal approaches, particularly the Sustainable Development Goals (SDGs) agenda.\n\n\n\n\nPolicy gaps in integrating SDGs into AMR planning and implementation.\n\n\n\nINFLUX project (ERC grant No.¬†101039376): Contributed to research investigating and establishing database of drivers responsible for the emergence of emerging pests and pathogens, assessing governmental responses and their cascading social-ecological effects.\nSUSTAIN project: Conducted statistical analysis to evaluate the effectiveness of bundled healthcare interventions targeting health workers in Nepal, aimed at enhancing neonatal care quality\n\n\n\n\n\n\nApplied Epi\n\n\nInstructor, Coordinator Jun 2021 ‚Äì Present\n\nInstructor: Provide R trainings for many epidemiologists worldwide. Provide public health services support including mentorship, outbreak response to AppliedEpi partners (i.e.¬†Doctors Without Borders ‚Äì MSF, Australian National University, WHO Philippines)\nTranslation Coordinator: Maintain translation packages and educational resources, including the Epi R Handbook (available in 10 languages), Epi Julia Handbook, slides, and tutorials\nCo-Author of Applied Epidemiology Manual (on-going project)\nLead translator the Vietnamese version of R for applied epidemiology and public health\n\n\n\n\nR training conducted by WHO for Philippines MoH.\n\n\n\n\n\n\n\nHanoi University of Public Health\n\n\nResearch Assistant, Center for Public Health and Ecosystem Research Jul 2018 ‚Äì Jul 2020\nSupported three research projects on sanitation, food safety, and disease prevention in Vietnam, focusing on light-touch interventions in pig farms, parasite prevalence in ethnic communities, and assessing disease risk factors at the human-animal-environment interface, including biosecurity practices, animal movement, human-animal contact, and antimicrobial resistance\nMain responsibilities included:\n\nParticipated in the design, monitoring, and evaluation of interventions\nAssisted in collecting samples in field and preparing samples at laboratory\nCollected and analyzed data, wrote reports and manuscripts for publication\nConducted risk communication campaigns about food-borne diseases and food safety\nConducted project administrative tasks, i.e.¬†contacting with local & international partners, applying ethical approval\n\n\n\n\nPresent research findings at Safepork conferece at Berlin 2019"
  },
  {
    "objectID": "cv.html#professional-experience",
    "href": "cv.html#professional-experience",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Uppsala University\n\n\nPhD student Oct 2021 ‚Äì Present\n\nPhD project: Analyzed the degree to which factors driving antimicrobial resistance (AMR) development and spread are addressed by AMR-specific policies and interventions versus broader societal approaches, particularly the Sustainable Development Goals (SDGs) agenda.\n\n\n\n\nPolicy gaps in integrating SDGs into AMR planning and implementation.\n\n\n\nINFLUX project (ERC grant No.¬†101039376): Contributed to research investigating and establishing database of drivers responsible for the emergence of emerging pests and pathogens, assessing governmental responses and their cascading social-ecological effects.\nSUSTAIN project: Conducted statistical analysis to evaluate the effectiveness of bundled healthcare interventions targeting health workers in Nepal, aimed at enhancing neonatal care quality\n\n\n\n\n\n\nApplied Epi\n\n\nInstructor, Coordinator Jun 2021 ‚Äì Present\n\nInstructor: Provide R trainings for many epidemiologists worldwide. Provide public health services support including mentorship, outbreak response to AppliedEpi partners (i.e.¬†Doctors Without Borders ‚Äì MSF, Australian National University, WHO Philippines)\nTranslation Coordinator: Maintain translation packages and educational resources, including the Epi R Handbook (available in 10 languages), Epi Julia Handbook, slides, and tutorials\nCo-Author of Applied Epidemiology Manual (on-going project)\nLead translator the Vietnamese version of R for applied epidemiology and public health\n\n\n\n\nR training conducted by WHO for Philippines MoH.\n\n\n\n\n\n\n\nHanoi University of Public Health\n\n\nResearch Assistant, Center for Public Health and Ecosystem Research Jul 2018 ‚Äì Jul 2020\nSupported three research projects on sanitation, food safety, and disease prevention in Vietnam, focusing on light-touch interventions in pig farms, parasite prevalence in ethnic communities, and assessing disease risk factors at the human-animal-environment interface, including biosecurity practices, animal movement, human-animal contact, and antimicrobial resistance\nMain responsibilities included:\n\nParticipated in the design, monitoring, and evaluation of interventions\nAssisted in collecting samples in field and preparing samples at laboratory\nCollected and analyzed data, wrote reports and manuscripts for publication\nConducted risk communication campaigns about food-borne diseases and food safety\nConducted project administrative tasks, i.e.¬†contacting with local & international partners, applying ethical approval\n\n\n\n\nPresent research findings at Safepork conferece at Berlin 2019"
  },
  {
    "objectID": "cv.html#education",
    "href": "cv.html#education",
    "title": "Curriculum Vitae",
    "section": " Education",
    "text": "Education\n\n\n\n\n\nUppsala University\n\n\nDoctoral degree in Global Health Oct 2021 ‚Äì Oct 2025\n\nThesis: Towards sustainable solutions for AMR: Targeting distal drivers through integrated SDG-policy and actions\n\n\n\n\n\n\nUniversity of Li√®ge\n\n\nSpecialized Master in Integrated Management of Health Risks in the Global South Sep 2020 ‚Äì Sep 2021\n\nGraduated with highest honor\nThesis: Operationalization and measurement of organizational adaptability: experiences from FRIENDSHIP, a non-governmental organization adapting to COVID-19 pandemic in Bangladesh\n\n\n\n\n\n\nHanoi Medical University\n\n\nBachelor of Public Health Sep 2013 ‚Äì Sep 2017\n\nGraduated with high honor\nGraduation thesis: 9.5/10"
  },
  {
    "objectID": "cv.html#communities-and-organizations",
    "href": "cv.html#communities-and-organizations",
    "title": "Curriculum Vitae",
    "section": " Communities and Organizations",
    "text": "Communities and Organizations\n The Association of Vietnamese Science and Technology Experts in Sweden (AVISE)\n Applied Epi Community\n GlobeLife"
  },
  {
    "objectID": "cv.html#publication",
    "href": "cv.html#publication",
    "title": "Curriculum Vitae",
    "section": " Publication",
    "text": "Publication\nLink to my Google Scholar profile (14 peer-reviewed, h-index: 7, i10-index: 4, total number of citations: 110)\nSelected 5 articles:\n\nLuong NT, Didier W, Mats M, Tiscar G, Peter SJ (2024) Characterizing proximal and distal drivers of antimicrobial resistance: An umbrella review. Journal of Global Antimicrobial Resistance\nLuong NT, Didier W, Mats M, Peter SJ (2024) Characterizing proximal and distal drivers of antimicrobial resistance: An umbrella review. Journal of Global Antimicrobial Resistance\nPeter SJ, Luong NT and 10 co-authors (2024). Association between national action and trends in antibiotic resistance: an analysis of 73 countries from 2000 to 2023\nNgo HTH, Nguyen TL, and 6 co-authors (2021). Microbial contamination and associated risk factors in retailed pork from key value chains in Northern Vietnam. Food Microbiology\nLam S, Huyen NTT, Ngo HTH, Nguyen TL, and 6 co-authors (2021). Unpacking the Theory Behind One Health Food Safety Programs: A Vietnam Case Study. Frontiers in Veterinary Science"
  },
  {
    "objectID": "cv.html#academic-events-attendance",
    "href": "cv.html#academic-events-attendance",
    "title": "Curriculum Vitae",
    "section": " Academic events attendance",
    "text": "Academic events attendance\n\n2024 Oral presentation: The Nordic AMR Centre Conference, Troms√∏, Norway\n2023 Poster presentation: EAR LTC-Sarea-ENLIGHT CONGRESS ‚ÄúStrengthening Antibiotic Resistance Networks‚Äù, Bordeaux, France\n2023 CIRCUS‚Äô Interdisciplinary Summer School, Uppsala, Sweden\n2022 MIRAI 2.0 Research and Innovation week 2022, Fukuoka, Japan\n2022 NorDoc PhD Summit and summer school, Bergen Norway\n2022 SweDev PhD conference, Gothenburg, Sweden\n2019 Poster presentation: 13th SafePork 2019: One Health ‚Äì Tear down interdisciplinary wall‚Äù conference, Berlin, Germany\n2019 Poster presentation: Regional symposium on research into smallholder pig production, and pork safety, Hanoi, Vietnam"
  },
  {
    "objectID": "cv.html#skills",
    "href": "cv.html#skills",
    "title": "Curriculum Vitae",
    "section": " Skills",
    "text": "Skills\nProfessional skills\n\nStatistical & Machine Learning Frameworks: Extensive experience with generalized linear mixed models, time series analysis, spatial statistics, network analysis, clustering techniques, natural language processing, and large language models\nEpidemiological Methods: Skilled in conducting systematic reviews and meta-analyses, health policy analysis, household surveys, data collection (including in-depth interviews, focus group discussions), and risk communication.\nSoftware Engineering: Advanced proficiency in using programming language for statistical analysis (R, Python, STATA), product communication (R Markdown, Quarto, Shiny and Power BI), database management & query (SQL), version control (Git, Github Action), web framework (HTML, CSS, JS), package development (R, TypeScript).\nData Management: Proficiency in field/clinical data management using Open Data Kit (ODK) and RedCap\nLaboratory techniques: Familiar with laboratory microbiological and molecular techniques including Salmonella isolation, Total Bacteria Count, ELISA and PCR\nProject Management: Budget planning, M&E skills, proposal writing\n\nPersonal skills\n\nInterdisciplinary, adaptability, organized, independent, innovative, optimistic, constructive\n\nLanguages\n\nVietnamese, English, Swedish"
  },
  {
    "objectID": "blog/2024-02-19_beginner-quarto-netlify/index.html",
    "href": "blog/2024-02-19_beginner-quarto-netlify/index.html",
    "title": "A beginner‚Äôs guide to building a simple website with Quarto & Netlify",
    "section": "",
    "text": "Are you eager to build a website but don‚Äôt have any web development experience or coding knowledge? Fear not! In this guide, I‚Äôll walk you through the process of creating a simple website using the Quarto visual editor and deploying it seamlessly with Netlify‚Äôs drag and drop tool."
  },
  {
    "objectID": "blog/2024-02-19_beginner-quarto-netlify/index.html#what-just-happened",
    "href": "blog/2024-02-19_beginner-quarto-netlify/index.html#what-just-happened",
    "title": "A beginner‚Äôs guide to building a simple website with Quarto & Netlify",
    "section": "2.1 What just happened?",
    "text": "2.1 What just happened?\nWhen we clicked Render Website, Quarto turns all of the .qmd files and styling sheets into HTML (HyperText Markup Language) source files that serve as the website. The website was rendered into the new folder _site. You can even click on any of the .html files and view it in your web browser to see how it looks. Every time we render the website, this _site folder gets updated."
  },
  {
    "objectID": "blog/2024-02-19_beginner-quarto-netlify/index.html#what-are-quarto-documents",
    "href": "blog/2024-02-19_beginner-quarto-netlify/index.html#what-are-quarto-documents",
    "title": "A beginner‚Äôs guide to building a simple website with Quarto & Netlify",
    "section": "3.1 What are Quarto documents?",
    "text": "3.1 What are Quarto documents?\nEach .qmd has a YAML (YAML Ain‚Äôt Markup Language) header for document-specific options and Markdown content. Quarto documents are authored using Markdown, which is a plain text format designed to be easy to write and easy to read. We‚Äôll use the visual editor in this tutorial, but you‚Äôll likely eventually need Markdown if you want more customization options. Reference the text formatting markdown syntax and output in this Markdown Basics article. You can also toggle between Source and Visual to see the underlying Markdown as you‚Äôre writing your Quarto documents."
  },
  {
    "objectID": "blog/2024-02-19_beginner-quarto-netlify/index.html#my-turn",
    "href": "blog/2024-02-19_beginner-quarto-netlify/index.html#my-turn",
    "title": "A beginner‚Äôs guide to building a simple website with Quarto & Netlify",
    "section": "4.1 My turn",
    "text": "4.1 My turn"
  },
  {
    "objectID": "blog/2024-02-19_beginner-quarto-netlify/index.html#your-turn",
    "href": "blog/2024-02-19_beginner-quarto-netlify/index.html#your-turn",
    "title": "A beginner‚Äôs guide to building a simple website with Quarto & Netlify",
    "section": "4.2 Your turn",
    "text": "4.2 Your turn\n\nOpen index.qmd.\nCheck Render on Save.\nChange the webpage title.\nSave the file (Cmd/Ctrl + S).\nDelete the example text and write some of your own.\nSave again."
  },
  {
    "objectID": "blog/2024-02-19_beginner-quarto-netlify/index.html#my-turn-1",
    "href": "blog/2024-02-19_beginner-quarto-netlify/index.html#my-turn-1",
    "title": "A beginner‚Äôs guide to building a simple website with Quarto & Netlify",
    "section": "5.1 My turn",
    "text": "5.1 My turn\nI like the jolla template. In my my-website project folder, I added a new folder called images for my pictures. This is optional - just be sure to match the file path.\n---\ntitle: \"Mai, Tai, and Skye\"\nimage: images/couch-kits.JPG\nabout:\n  template: jolla\n  links:\n    - icon: instagram\n      text: Instagram\n      href: https://www.instagram.com/piggies.and.kits\n---"
  },
  {
    "objectID": "blog/2024-02-19_beginner-quarto-netlify/index.html#your-turn-1",
    "href": "blog/2024-02-19_beginner-quarto-netlify/index.html#your-turn-1",
    "title": "A beginner‚Äôs guide to building a simple website with Quarto & Netlify",
    "section": "5.2 Your turn",
    "text": "5.2 Your turn\n\nOpen about.qmd.\nCheck Render on Save, and save after each below step to update the preview.\nUpdate the title to your name or organization.\nAdd the about option to the YAML. Check out the previews of the templates and choose which one you like best.\nAdd a photo to your project folder or to a subfolder, and then add the file path to that photo to the image: option.\nAdd any social media or other websites you like to the links: option. Optionally, you can use Bootstrap icons.\n\n\n\n\n\n\n\nTip\n\n\n\nIf you want to use the special about template as your home page, you can add the about YAML option to index.qmd. In fact, the about: option can be used for any .qmd document for your website!"
  },
  {
    "objectID": "blog/2024-02-19_beginner-quarto-netlify/index.html#my-turn-2",
    "href": "blog/2024-02-19_beginner-quarto-netlify/index.html#my-turn-2",
    "title": "A beginner‚Äôs guide to building a simple website with Quarto & Netlify",
    "section": "6.1 My turn",
    "text": "6.1 My turn\nI named my new page birthdays because I‚Äôm adding pictures from Mai‚Äôs, Tai‚Äôs, and Skye‚Äôs birthday party ü•≥.\n\nThis new page opened completely blank. From the Insert menu of the editor toolbar, I selected YAML Block, to which I added the page title.\n\nI added headings and images for our family picture and each of our three cats. For more advanced figure layouts, see this Quarto article.\n\nVisualSource"
  },
  {
    "objectID": "blog/2024-02-19_beginner-quarto-netlify/index.html#your-turn-2",
    "href": "blog/2024-02-19_beginner-quarto-netlify/index.html#your-turn-2",
    "title": "A beginner‚Äôs guide to building a simple website with Quarto & Netlify",
    "section": "6.2 Your turn",
    "text": "6.2 Your turn\n\nCreate a new Quarto document.\nAdd the YAML Block.\nAdd a page title.\nAdd some content to your page.\nRender the page.\nBuild and look at the website.\n\nNotice that your new page isn‚Äôt included on the website! Fix this by adding it to _quarto.yml."
  },
  {
    "objectID": "blog/2024-02-19_beginner-quarto-netlify/index.html#my-turn-3",
    "href": "blog/2024-02-19_beginner-quarto-netlify/index.html#my-turn-3",
    "title": "A beginner‚Äôs guide to building a simple website with Quarto & Netlify",
    "section": "7.1 My turn",
    "text": "7.1 My turn\nIn _quarto.yml, I changed the website title, changed the text for the link to the about page, and added the birthdays page to the navigation bar.\n\nUpdatedDefault\n\n\n\nwebsite:\n  title: \"MTS -- The Best Kits!\"\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - href: about.qmd\n        text: About\n      - href: birthdays.qmd\n        text: Birthday\n\n\n\nwebsite:\n  title: \"my-website\"\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - about.qmd"
  },
  {
    "objectID": "blog/2024-02-19_beginner-quarto-netlify/index.html#your-turn-3",
    "href": "blog/2024-02-19_beginner-quarto-netlify/index.html#your-turn-3",
    "title": "A beginner‚Äôs guide to building a simple website with Quarto & Netlify",
    "section": "7.2 Your turn",
    "text": "7.2 Your turn\n\nOpen _quarto.yml.\nChange the website title.\nOptionally, update the text for the link to the about page.\nAdd a new entry for the new page you added.\nRender."
  },
  {
    "objectID": "blog/2024-02-19_beginner-quarto-netlify/index.html#my-turn-4",
    "href": "blog/2024-02-19_beginner-quarto-netlify/index.html#my-turn-4",
    "title": "A beginner‚Äôs guide to building a simple website with Quarto & Netlify",
    "section": "8.1 My turn",
    "text": "8.1 My turn\nI previewed the minty, quartz, and solar themes.\n\nmintyquartzsolar"
  },
  {
    "objectID": "blog/2024-02-19_beginner-quarto-netlify/index.html#your-turn-4",
    "href": "blog/2024-02-19_beginner-quarto-netlify/index.html#your-turn-4",
    "title": "A beginner‚Äôs guide to building a simple website with Quarto & Netlify",
    "section": "8.2 Your turn",
    "text": "8.2 Your turn\n\nGo to Bootswatch project and see which themes you like.\nOpen _quarto.yml, and try them out. Make sure to re-render to update the preview."
  },
  {
    "objectID": "blog/2024-02-19_beginner-quarto-netlify/index.html#my-turn-5",
    "href": "blog/2024-02-19_beginner-quarto-netlify/index.html#my-turn-5",
    "title": "A beginner‚Äôs guide to building a simple website with Quarto & Netlify",
    "section": "9.1 My turn",
    "text": "9.1 My turn\nI already have a Netlify account. So I logged in and opened the Sites tab. Then I dragged & dropped my _site folder into the ... or deploy manually box.\n\nAfter the _site folder uploaded, a Deploy success! message displayed. Notice Netlify generated a random subdomain name2. I‚Äôll change this in the next step.\n\nI opened the Site Configuration tab, and opened the live website by clicking either the link (https://jade-donut-3a47e4.netlify.app/) or the preview thumbnail.\nThe auto-generated name is way too long and irrelevant to what my website is about. I renamed it by going to Site details and then Change site name.\n\nI changed the site name to maitaiskye so the URL for my website is https://maitaiskye.netlify.app/. The netlify.app part is not optional, unless you buy your own domain name.\n\nNow we can see my website is live!"
  },
  {
    "objectID": "blog/2024-02-19_beginner-quarto-netlify/index.html#your-turn-5",
    "href": "blog/2024-02-19_beginner-quarto-netlify/index.html#your-turn-5",
    "title": "A beginner‚Äôs guide to building a simple website with Quarto & Netlify",
    "section": "9.2 Your turn",
    "text": "9.2 Your turn\n\nIf you don‚Äôt yet have a Netlify account, sign up and log in.\nGo to the Sites tab to access the drag & drop tool and upload your _site folder.\nOpen and check out your newly deployed site.\nGo to Site configuration to change your site name.\nCongratulations! Your website is live! üéâ"
  },
  {
    "objectID": "blog/2024-02-19_beginner-quarto-netlify/index.html#buy-your-own-url",
    "href": "blog/2024-02-19_beginner-quarto-netlify/index.html#buy-your-own-url",
    "title": "A beginner‚Äôs guide to building a simple website with Quarto & Netlify",
    "section": "9.3 Buy your own URL",
    "text": "9.3 Buy your own URL\nIf you don‚Äôt want the netlify.app suffixed to your site name, you‚Äôll need to purchase your own domain. Instead of Site configuration, go to Domain management, and then click Add a domain.\n\nEnter whatever custom domain you want. There are a bajillion different extensions ‚Äì domain.com lists them alphabetically and has a helpful FAQ about domain extensions. maitaiskye.com is available for $13.99 for the first year."
  },
  {
    "objectID": "blog/2024-02-19_beginner-quarto-netlify/index.html#footnotes",
    "href": "blog/2024-02-19_beginner-quarto-netlify/index.html#footnotes",
    "title": "A beginner‚Äôs guide to building a simple website with Quarto & Netlify",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nGenerally, it‚Äôs good practice to not include special characters or spaces in the folder or file names. For example, if you want to name your website ‚ÄúMy Website!!!‚Äù, name the folder ‚Äúmy-website‚Äù. Later, we will change how the website name displays in our configuration files.‚Ü©Ô∏é\nThis subdomain name is what comes before the netlify.app domain for the free tier of Netlify. I changed mine to maitaiskye, so the URL is maitaiskye.netlify.app.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/2023-11-19_publish-quarto-website/index.html",
    "href": "blog/2023-11-19_publish-quarto-website/index.html",
    "title": "Intermediate guide to publish a Quarto website with GitHub & Netlify",
    "section": "",
    "text": "Thankfully, many amazing resources for building beautiful websites and blogs with Quarto already exist. Instead of adding to that pool of content, I‚Äôll demo how I built my website with Quarto, connected to a GitHub repository, and then deployed and published with Netlify continuous deployment. Special thanks to Libby Heeren for testing this demo and helping me clarify some sticky points! ‚ô•Ô∏è\nI struggled for hours trying to set up the configurations so my site would deploy every time I pushed a change to my GitHub repo. Hopefully this demo saves you some time when you start your own website! :)\nAs with most tech and dev stuff, there‚Äôs many ways to do (almost) the same thing. I‚Äôd love to hear how other people have their Quarto/Netlify workflows set up. Leave a comment at the end of the post, or reach out!\nAnyhoo, keep on reading to learn about:"
  },
  {
    "objectID": "blog/2023-11-19_publish-quarto-website/index.html#site-domain-name",
    "href": "blog/2023-11-19_publish-quarto-website/index.html#site-domain-name",
    "title": "Intermediate guide to publish a Quarto website with GitHub & Netlify",
    "section": "\n3.1 Site domain name",
    "text": "3.1 Site domain name\nThe domain name is the URL or web address to our site. We have two options to rename our site:\n\n\nFree: change the random name provided but keep the netlify.app domain.\n\nPurchase a new domain: I recommend buying it directly on Netlify so they handle all the DNS configurations. Or, buy from a domain provider that doesn‚Äôt use the NS1 DNS zone, or you might go through the nightmare of switching DNS zones.5\n\n\nFree domain name change\nLet‚Äôs walk through the free option first.\nFrom the site overview Netlify page, click on Site configuration.\n\nScroll down to Site information, and then click on Change site name.\n\nNow we can update the site name and click Save:\n\nNote our site name is just the prefix to the full URL containing netlify.app.\nBuy a domain name\nIf you don‚Äôt want the netlify.app domain, you can purchase your own. Instead of Site configuration, go to Domain management, and then click Add a domain.\n\nType in whatever custom domain we want. There are a bajillion different extensions ‚Äì domain.com lists them alphabetically and has a helpful FAQ about domain extensions. my-website24.com is available for $13.99 for the first year."
  },
  {
    "objectID": "blog/2023-11-19_publish-quarto-website/index.html#new-_publish.yml-file",
    "href": "blog/2023-11-19_publish-quarto-website/index.html#new-_publish.yml-file",
    "title": "Intermediate guide to publish a Quarto website with GitHub & Netlify",
    "section": "\n3.2 New _publish.yml file",
    "text": "3.2 New _publish.yml file\nNow that we‚Äôre set up with Netlify and GitHub, let‚Äôs head back to RStudio. Notice this new file _publish.yml appeared in the project directory when we used the quarto publish netlify command:\n\n\n_publish.yml\n\n- source: project\n  netlify:\n    - id: b9f73a69-06e7-4de2-9c7b-4f9855b56ba3\n      url: 'https://stately-chimera-0c91c7.netlify.app'\n\nThe Netlify site ID and original random URL were automatically filled in.\nThe next time we manually publish from the terminal, it will ask if we want to publish the update to https://my-website24.netlify.app. If we enter y, it will update the url value in the _publish.yml file.\n\n\nTerminal\n\n(base) MacBook-Pro-4:my-website jadeyryan$ quarto publish netlify\n? Publish update to: ‚Ä∫ https://stately-chimera-0c91c7.netlify.app (Netlify - jadey.nicole.ryan@gmail.com)\nRendering for publish:\n\n[1/2] index.qmd\n[2/2] about.qmd\n\n[‚úì] Preparing to publish site\n[‚úì] Uploading files (complete)\n[‚úì] Deploying published site\n[‚úì] Published site: https://stately-chimera-0c91c7.netlify.app\n\n(base) MacBook-Pro-4:my-website jadeyryan$ quarto publish netlify\n? Publish update to: ‚Ä∫ https://my-website24.netlify.app (Netlify - jadey.nicole.ryan@gmail.com)\nRendering for publish:\n\n[1/2] index.qmd\n[2/2] about.qmd\n\n[‚úì] Preparing to publish site\n[‚úì] Uploading files (complete)\n[‚úì] Deploying published site\n[‚úì] Published site: https://my-website24.netlify.app\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you continue to the next steps for configuring continuous deployment, this should be your last time manually publishing your site with quarto publish netlify in the terminal.\nWhen adding code content, you should still run quarto render in the terminal to update the _freeze directory. Though, it‚Äôs good practice to always render before pushing to GitHub."
  },
  {
    "objectID": "blog/2023-11-19_publish-quarto-website/index.html#configure-netlify-plugin",
    "href": "blog/2023-11-19_publish-quarto-website/index.html#configure-netlify-plugin",
    "title": "Intermediate guide to publish a Quarto website with GitHub & Netlify",
    "section": "\n4.1 Configure Netlify plugin",
    "text": "4.1 Configure Netlify plugin\nThe Quarto Netlify plugin installs Quarto on the Netlify build server, allowing Netlify to build our Quarto website.\nLet‚Äôs create the netlify.toml and package.json files in our RStudio project and copy/paste the below content into these files.\n\n\nnetlify.toml\n\n[[plugins]]\npackage = \"@quarto/netlify-plugin-quarto\"\n\n\n\npackage.json\n\n{\n  \"dependencies\": {\n    \"@quarto/netlify-plugin-quarto\": \"^0.0.5\"\n  }\n}"
  },
  {
    "objectID": "blog/2023-11-19_publish-quarto-website/index.html#freeze-computations",
    "href": "blog/2023-11-19_publish-quarto-website/index.html#freeze-computations",
    "title": "Intermediate guide to publish a Quarto website with GitHub & Netlify",
    "section": "\n4.2 Freeze computations",
    "text": "4.2 Freeze computations\nWe need to freeze computations so code only runs locally. When we render a .qmd that executes code on our local machine, the results get saved in a html.json file within the _freeze directory. This means that the CI server has access to the code output and doesn‚Äôt need to execute any of the code.\nThe _freeze directory and all its files must be committed to our repo. Otherwise, the build will fail because Netlify doesn‚Äôt have the code output and can‚Äôt execute code without R installed. See the detailed error in my comment on a GitHub issue.\nTo automatically freeze all computations, add these two lines to our _quarto.yml file:\n\n\n_quarto.yml\n\nexecute:\n  freeze: auto\n\nSetting freeze: auto tells Quarto to only re-render code when the source changes.\nIf you need to execute code within a CI service, see the Quarto docs for example GitHub Actions that install Quarto, R, and all dependencies."
  },
  {
    "objectID": "blog/2023-11-19_publish-quarto-website/index.html#ignore-output-directory",
    "href": "blog/2023-11-19_publish-quarto-website/index.html#ignore-output-directory",
    "title": "Intermediate guide to publish a Quarto website with GitHub & Netlify",
    "section": "\n4.3 Ignore output directory",
    "text": "4.3 Ignore output directory\nBecause we want Netlify bots to use continuous deployment to build our site, we need to ignore our output directory. To do this, we add the _site directory that contains all the rendered website content to our .gitignore file. This is recommended in the Quarto docs to avoid super messy diffs and potential merge conflicts.\n\n\n.gitignore\n\n/_site/\n\n\n\n\n\n\n\nNote\n\n\n\nIf you‚Äôre not following the workflow in this blog post and instead are using the Local Execution & Rendering option of the CI continuum described in the Quarto docs, do not add _site to your .gitignore. You need this directory checked into version control so Netlify can access this content to publish your website."
  },
  {
    "objectID": "blog/2023-11-19_publish-quarto-website/index.html#link-netlify-site-to-github-repository",
    "href": "blog/2023-11-19_publish-quarto-website/index.html#link-netlify-site-to-github-repository",
    "title": "Intermediate guide to publish a Quarto website with GitHub & Netlify",
    "section": "\n4.4 Link Netlify site to GitHub repository",
    "text": "4.4 Link Netlify site to GitHub repository\nWe already connected our Netlify and GitHub accounts, but now we need to tell Netlify which GitHub repo provides the source code for our website.\nOn Netlify, go to Site configuration &gt; Build & deploy &gt; Continous deployment &gt; Link repository.\n\nChoose Deploy with GitHub:\n\nIf you‚Äôre already logged into GitHub, it should immediately authorize and allow you to select which repositories the Netlify app can access.\nIf this is your first time deploying with Netlify and GitHub, you‚Äôll likely need to click the bottom link Configure the Netlify app on GitHub. This should open a new window where you can make sure the Netlify app is installed on your GitHub and select which repositories it can access.\n\nAfter selecting the correct repository, configure the build settings on the next screen. Enter _site in the Publish directory field:\n\nThen click Deploy my-website24, which take us back to our site overview page where it now says Deploys from GitHub instead of Manual deploys."
  },
  {
    "objectID": "blog/2023-11-19_publish-quarto-website/index.html#push-a-change-to-our-repo",
    "href": "blog/2023-11-19_publish-quarto-website/index.html#push-a-change-to-our-repo",
    "title": "Intermediate guide to publish a Quarto website with GitHub & Netlify",
    "section": "\n4.5 Push a change to our repo",
    "text": "4.5 Push a change to our repo\nLet‚Äôs push a change to our repo and make sure it automatically redeploys and republishes our website!\nAdd some content to about.qmd, run quarto render in the terminal, and then push to main.\n\nThe Deploys page on Netlify tells us that we successfully published from main@0b8b526.\n\nAuto publishing\nBy default, auto publishing is turned on in the Netlify deploy settings. This means all successful deployments are automatically published to the public site.\nOptionally, you can turn this setting off so that you have to click Publish to send the deployment to production. If you do want to turn it off, go to Deploys &gt; and then click Lock to stop auto publishing.\n\nThe site will still deploy every time you push changes to your repo, but you need to click a button to actually publish this latest deployment. This is a good option if you don‚Äôt want to work in new branches or use pull requests/merges, but still want to preview your site before sending it to production.\nFor my personal website, I don‚Äôt have this turned off so that the site will automatically publish anytime I push to GitHub. Otherwise I might forget to click Publish and wonder where my changes are üòÖ.\nNetlify docs provide more detail about auto publishing."
  },
  {
    "objectID": "blog/2023-11-19_publish-quarto-website/index.html#branch-deploys",
    "href": "blog/2023-11-19_publish-quarto-website/index.html#branch-deploys",
    "title": "Intermediate guide to publish a Quarto website with GitHub & Netlify",
    "section": "\n5.1 Branch deploys",
    "text": "5.1 Branch deploys\nBranch deploys are great if you typically use feature branches in your workflow.\nBy default, only the production branch (typically main) is automatically deployed by Netlify.\nTo enable branch deploys on other branches, we need to change the branch deploy setting. On the Netlify website &gt; Site Configuration &gt; Build & deploy &gt; Continuous deployment &gt; Branches and deploy contexts &gt; Branch deploys &gt; Configure &gt; select the All radio button &gt; and then click Save.\n\nOr, if we only want to deploy previews for a specific branch, select Let me add individual branches and then enter the name of that branch.\nLet‚Äôs try it out by creating a new branch called staging and pushing a commit to it.\nOn the Netlify Deploys page, we see our live site is still published from main, but we now have a Branch deploy from the staging branch that we can click to preview.\n\nOnce we merge our staging branch into main, those changes will be published to our site in production."
  },
  {
    "objectID": "blog/2023-11-19_publish-quarto-website/index.html#deploy-previews",
    "href": "blog/2023-11-19_publish-quarto-website/index.html#deploy-previews",
    "title": "Intermediate guide to publish a Quarto website with GitHub & Netlify",
    "section": "\n5.2 Deploy previews",
    "text": "5.2 Deploy previews\nDeploy previews are enabled by default once our Netlify site is linked with our GitHub repository. Every time we make a pull request or merge, Netlify will deploy our site and then provide the links to the deploy information as a comment in the pull request/merge conversation on GitHub.\nFrom our GitHub repository, create a pull request to merge our staging branch into main.\nThis triggers Netlify to deploy the site and then comment all the information for the deploy preview including a link to the commit, the deploy log, preview link, and a QR code to preview on a mobile device.\n\nWe can also access our deploy preview from the Netlify Deploys page. Similar to the branch deploy, our live site is still published from main, but we now have Deploy Preview #2 from staging. The #2 just means this was the second pull/merge request in our repository.\n\nOnce we complete our pull request and merge to main, those changes will be published to our site in production."
  },
  {
    "objectID": "blog/2023-11-19_publish-quarto-website/index.html#footnotes",
    "href": "blog/2023-11-19_publish-quarto-website/index.html#footnotes",
    "title": "Intermediate guide to publish a Quarto website with GitHub & Netlify",
    "section": "Footnotes",
    "text": "Footnotes\n\nSee my GitHub stars list for my favorite blogs or Quarto website resources.‚Ü©Ô∏é\nAs long we Configure Netlify plugin.‚Ü©Ô∏é\nUnless we have a GitHub Action install R and package dependencies.‚Ü©Ô∏é\nCheck out my GitHub issue comment to see what happens if we don‚Äôt have freeze set to auto or true AND commit the freeze outputs.‚Ü©Ô∏é\nI originally bought a domain from Square Space and could not set my Netlify site to that domain due to DNS issues that I don‚Äôt fully understand. When trying to add a domain, Netlify gave this error message: A DNS zone for this domain already exists on NS1, the DNS provider backing Netlify DNS. Please contact NS1 with the domain name for support. Here‚Äôs a support forum thread on Netlify with the instructions for pointing a custom domain to a Netlify site. I ended up buying another domain directly from Netlify‚Ä¶ DNS stuff is too confusing! üòµ‚Äçüí´‚Ü©Ô∏é\nWe‚Äôve already connected our GitHub account to our Netlify in Create and connect to GitHub and Connect and publish to Netlify, but we still need to pick which repository our Netlify site links to.‚Ü©Ô∏é\nSet up branch deploys by going to Netlify.com &gt; [Your website] &gt; Site configuration &gt; Build & deploy &gt; Continuous Deployment &gt; Branches and deploy contexts‚Ü©Ô∏é"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "The Data Alchemist",
    "section": "",
    "text": "‚ÄúWelcome, adventurer! I‚Äôm thrilled you‚Äôve joined me on this journey through the world of data science and code. Here, I‚Äôll share the discoveries I‚Äôm making, the projects I‚Äôm building, and the curiosities I‚Äôm exploring‚Äîsprinkled with a little feline charm along the way. Let‚Äôs learn and uncover insights together!‚Äù\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSwitching from R to Python: A Beginner‚Äôs Guide to Equivalent Tools\n\n\n\n\n\n\nPython\n\n\nR\n\n\nData Science\n\n\n\nLearn how to transition from R to Python seamlessly with tools that match your R favorites like dplyr, ggplot2, Shiny, and more.\n\n\n\n\n\nNov 28, 2024\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nData frame wars: Choosing a Python dataframe library as a dplyr user\n\n\n\n\n\n\nR\n\n\nPython\n\n\n\n\n\n\n\n\n\nJan 25, 2023\n\n\n17 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Luong Nguyen Thanh",
    "section": "",
    "text": "GitHub\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Research Profile"
  },
  {
    "objectID": "index.html#hi-there",
    "href": "index.html#hi-there",
    "title": "Luong Nguyen Thanh",
    "section": "Hi there!",
    "text": "Hi there!\nWelcome to my website ‚Äî I‚Äôm glad you‚Äôre here!\nI‚Äôm currently a PhD student at Uppsala University, following an academic path rooted in health and sustainability sciences, with degrees in Public Health (BPH) and One Health and Global Health (MSc).\nBeyond academia, I am passionate about programming, especially in R, with experience building packages, dashboards, Shiny apps, and working with large language models. My technical skills also extend to intermediate Python and foundational knowledge of SQL, HTML, CSS, and JavaScript. I‚Äôm especially interested in reproducibility and open science, and finding ways to streamline workflow.\nMy guiding principles in life are kindness, discipline, and integrity. I have found genuine fulfillment in working within the health and sustainability data science field, where I have the opportunity to engage with an inspiring community of like-minded professionals.\nIn my spare time, I love exploring history and diving into subjects related to religion and culture."
  },
  {
    "objectID": "projects/amr_sdg.html",
    "href": "projects/amr_sdg.html",
    "title": "AMR-SDGs interactions",
    "section": "",
    "text": "App  Code\nThe ShinyApp is the supplementary materials for the article:\n‚ÄúWhen Global Health meets Global Goals‚Äù: A comparative analysis the alignment between National Action Plans for AMR and Sustainable Development\nLuong Nguyen-Thanh1,2,4, Didier Wernli3, Mats M√•lqvist1, Peter S√∏gaard J√∏rgensen1,4,5\nAffiliations:\n1 SWEDESD ‚Äì Sustainability Learning and Research Center, Department of Women‚Äôs and Children‚Äôs Health, Uppsala University, Uppsala, Sweden\n2 Uppsala Antibiotic Centre (UAC), Uppsala University\n3 Global Studies Institute and Faculty of Science, University of Geneva, Geneva, Switzerland\n4 Global Economic Dynamics and the Biosphere, Royal Swedish Academy of Sciences, Stockholm, Sweden\n5 Stockholm Resilience Centre, Stockholm University, Stockholm, Sweden\n\n\n\nScreenshot from the App"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "{aetranslations}\n\n\n\nR package\n\n\n\nThis package hosts functions and guidelines for translating Applied Epi courses and resources\n\n\n\nOct 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nAMR Global Trend\n\n\n\nShiny app\n\n\n\nAMR Global Trend: A shiny app for exploring the global trend of AMR indicators from 73 countries\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nAMR-SDGs interactions\n\n\n\nShiny app\n\n\n\nAMR-SDGs Explorer: A shiny app for exploring the interaction between AMR and SDGs agenda in national policies\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/2021-11-14_setac_insecticides_water/index.html",
    "href": "talks/2021-11-14_setac_insecticides_water/index.html",
    "title": "Aquatic Risk Assessment: Organophosphate insecticide mixtures in Washington surface waters",
    "section": "",
    "text": "Slides\n\nDetails\nüìÜ November 14, 2021 // 12-minute recording\nüè® Virtual\nüå† Society of Environmental Toxicology and Chemistry (SETAC) North America 42nd Annual Meeting\n\n\nAbstract\nEcological risk assessments often do not consider potential additive, synergistic, or antagonistic effects from mixtures of chemicals and instead typically base risk on a single chemical. In the last decade, more tools and models have been developed to consider the interactive effects of chemicals within a mixture when conducting risk assessments. Therefore, this study uses actual environmental concentrations measured in 2018 and 2019 from the Washington State Department of Agriculture‚Äôs Surface Water Monitoring Program. Aquatic risk from exposure was assessed from chlorpyrifos, diazinon, and malathion (as individual chemicals and as binary and ternary mixtures) using the concentration addition model. These pesticides were selected because they have a common mechanism of toxicity, are frequently detected in surface waters in Washington, and were recently evaluated in a biological opinion by the National Marine Fisheries Service.\nAll detected concentrations of chlorpyrifos and malathion, assessed as individual chemicals, exceeded the predicted no effect concentration, indicating potential for adverse effects on aquatic life. Further, risk quotients for all binary and ternary mixtures were greater than one, also indicative of potential for adverse effects on aquatic life. In all samples containing a mixture, the maximum cumulative ratio suggested that a single insecticide contributed &gt;50% of the overall toxicity of each mixture. Based on the individual and mixture risk quotients, chlorpyrifos and malathion were the primary drivers of the toxicity of each mixture.\n\n\nSlides\n\n\nOops! Your browser doesn‚Äôt seem to support embedded PDFs.\n\n\nTry downloading instead.\n\n\n\n\n\n\nCitationBibTeX citation:@online{ryan2021,\n  author = {Ryan, Jadey},\n  title = {Aquatic {Risk} {Assessment:} {Organophosphate} Insecticide\n    Mixtures in {Washington} Surface Waters},\n  date = {2021-11-14},\n  url = {https://ntluong95.github.io/profile/talks/2021-11-14_setac_insecticides_water/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRyan, Jadey. 2021. ‚ÄúAquatic Risk Assessment: Organophosphate\nInsecticide Mixtures in Washington Surface Waters.‚Äù November 14,\n2021. https://ntluong95.github.io/profile/talks/2021-11-14_setac_insecticides_water/."
  },
  {
    "objectID": "talks/2024-11-17_avise_seminar_01/index.html",
    "href": "talks/2024-11-17_avise_seminar_01/index.html",
    "title": "How to keep information ‚Äòfresh‚Äô",
    "section": "",
    "text": "Recorded\n\nDetails\nüìÜ November 17, 2024 // 2:00 pm - 3:00 pm CET\nüè® Virtual\nüå† The Association of Vietnamese Science and Technology Experts in Sweden\n\n\nAbstract\nWireless communication not only facilitates the transmission of information between mobile users but also serves as a stepping stone for delivering information to subsequent processing points in an intelligent system. In this context, the goal of communication extends beyond ensuring accuracy and continuity to maintaining the value of information. This value can be measured by the freshness of information.\nThe talk will introduce the concept of the ‚Äúage of information‚Äù‚Äîa metric used to assess the freshness of information‚Äîand analyze this metric within a random multi-access system involving numerous devices. The content of the talk is designed for a general audience and does not require a technical background.\n\n\nScreenshot\n\n\n\n\n\nCitationBibTeX citation:@online{nguyen_thanh2024,\n  author = {Nguyen Thanh, Luong},\n  title = {How to Keep Information ‚ÄúFresh‚Äù},\n  date = {2024-11-17},\n  url = {https://ntluong95.github.io/profile/talks/2024-11-17_avise_seminar_01/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nNguyen Thanh, Luong. 2024. ‚ÄúHow to Keep Information\n‚ÄòFresh‚Äô.‚Äù November 17, 2024. https://ntluong95.github.io/profile/talks/2024-11-17_avise_seminar_01/."
  },
  {
    "objectID": "blog/2024-11-28_transition_to_python/index.html",
    "href": "blog/2024-11-28_transition_to_python/index.html",
    "title": "Switching from R to Python: A Beginner‚Äôs Guide to Equivalent Tools",
    "section": "",
    "text": "Transitioning from R to Python can feel like a daunting leap, especially if you‚Äôve grown comfortable with R‚Äôs ecosystem. The good news? Python offers several tools and libraries that mimic the syntax and functionality of your favorite R packages. Let‚Äôs explore these equivalents to ease your journey."
  },
  {
    "objectID": "blog/2024-11-28_transition_to_python/index.html#data-manipulation-ibis",
    "href": "blog/2024-11-28_transition_to_python/index.html#data-manipulation-ibis",
    "title": "Switching from R to Python: A Beginner‚Äôs Guide to Equivalent Tools",
    "section": "2.1 Data Manipulation: ibis",
    "text": "2.1 Data Manipulation: ibis\nIn R, dplyr and dbplyr are go-to packages for data manipulation, offering a clean, declarative syntax to filter, mutate, summarize, and join datasets. Python‚Äôs ibis serves as an excellent alternative, providing a similar experience for working with structured data.\nWhat sets ibis apart is its performance optimization. It abstracts SQL-like operations and enables you to specify a backend engine, such as DuckDB, Polars, or Pandas. This allows for efficient in-memory data processing or seamless database querying without switching languages. Whether you‚Äôre dealing with small data or large-scale analytics, ibis scales beautifully.\nTo get started, explore this dplyr-to-ibis tutorial, which maps your familiar R syntax to ibis equivalents."
  },
  {
    "objectID": "blog/2024-11-28_transition_to_python/index.html#data-visualization-plotnine",
    "href": "blog/2024-11-28_transition_to_python/index.html#data-visualization-plotnine",
    "title": "Switching from R to Python: A Beginner‚Äôs Guide to Equivalent Tools",
    "section": "2.2 Data Visualization: plotnine",
    "text": "2.2 Data Visualization: plotnine\nggplot2 is beloved in the R community for its intuitive grammar of graphics, enabling users to create complex, layered visualizations with minimal effort. If you‚Äôve relied on ggplot2 for your data storytelling, Python‚Äôs plotnine is your best friend.\nplotnine mirrors ggplot2‚Äôs syntax almost exactly. It supports layering plots with +, theming options, faceting for multi-panel plots, and customization of aesthetics. As a bonus, Python‚Äôs ecosystem integrates well with other visualization libraries, such as Matplotlib and Seaborn, for additional flexibility.\nDive into these plotnine tutorials to recreate your favorite ggplot2 visualizations in Python."
  },
  {
    "objectID": "blog/2024-11-28_transition_to_python/index.html#interactive-web-apps-shiny-for-python",
    "href": "blog/2024-11-28_transition_to_python/index.html#interactive-web-apps-shiny-for-python",
    "title": "Switching from R to Python: A Beginner‚Äôs Guide to Equivalent Tools",
    "section": "2.3 Interactive Web Apps: Shiny for Python",
    "text": "2.3 Interactive Web Apps: Shiny for Python\nShiny revolutionized how R users build interactive web applications with minimal code. The good news is that Shiny for Python brings the same simplicity to Python, letting you create interactive dashboards, data visualizations, and applications to showcase your work.\nShiny for Python follows a reactive programming paradigm, where outputs automatically update when inputs change. With Python‚Äôs robust backend options and Shiny‚Äôs UI capabilities, you can build powerful applications for both internal and external stakeholders. Whether you‚Äôre demonstrating a machine learning model or building a tool for non-technical audiences, Shiny has you covered.\nCheck out this Shiny for Python guide to start building your first app."
  },
  {
    "objectID": "blog/2024-11-28_transition_to_python/index.html#deploy-machine-learning-models-vetiver",
    "href": "blog/2024-11-28_transition_to_python/index.html#deploy-machine-learning-models-vetiver",
    "title": "Switching from R to Python: A Beginner‚Äôs Guide to Equivalent Tools",
    "section": "2.4 Deploy Machine Learning Models: Vetiver",
    "text": "2.4 Deploy Machine Learning Models: Vetiver\nDeploying machine learning models can often be complex and time-consuming. R‚Äôs vetiver package streamlines this process by creating APIs for your models, and Vetiver for Python does the same, making deployment accessible and consistent.\nWith Vetiver, you can deploy models built using scikit-learn, TensorFlow, PyTorch, or even custom algorithms. It generates prediction endpoints with minimal setup, allowing you to integrate your models into web applications, APIs, or automation workflows. This simplifies the journey from model development to production.\nLearn more about deploying models with vetiver in this comprehensive tutorial."
  },
  {
    "objectID": "blog/2024-11-28_transition_to_python/index.html#publishing-reports-quarto",
    "href": "blog/2024-11-28_transition_to_python/index.html#publishing-reports-quarto",
    "title": "Switching from R to Python: A Beginner‚Äôs Guide to Equivalent Tools",
    "section": "2.5 Publishing Reports: Quarto",
    "text": "2.5 Publishing Reports: Quarto\nR Markdown users transitioning to Python will be delighted to know that Quarto supports Python as well. Quarto extends the capabilities of R Markdown, enabling you to create HTML, PDF, and Word reports seamlessly. It even allows mixing code from Python, R, and Julia in the same document.\nQuarto offers numerous customization options, such as beautiful themes and dynamic content embedding, making it a versatile tool for technical reports, academic papers, and blog posts. As your projects grow, you can also use Quarto for building websites or books.\nExplore how to use Python with Quarto in this getting started guide."
  },
  {
    "objectID": "blog/2024-11-28_transition_to_python/index.html#an-ide-for-both-worlds-positron",
    "href": "blog/2024-11-28_transition_to_python/index.html#an-ide-for-both-worlds-positron",
    "title": "Switching from R to Python: A Beginner‚Äôs Guide to Equivalent Tools",
    "section": "2.6 An IDE for Both Worlds: Positron",
    "text": "2.6 An IDE for Both Worlds: Positron\nMany R users prefer RStudio for its clean, feature-rich interface. Fortunately, Positron, developed by Posit (formerly RStudio), provides a similar experience for Python. This integrated development environment (IDE) supports both R and Python, making it perfect for multi-language projects.\nWith Positron, you can enjoy a consistent environment for coding, debugging, and project management. Its features include a robust editor, version control integration, and support for Quarto documents. Download Positron from its GitHub repository and see how it complements your Python workflow."
  },
  {
    "objectID": "blog/2024-11-01_dplyr_candidate/index.html",
    "href": "blog/2024-11-01_dplyr_candidate/index.html",
    "title": "Data frame wars: Choosing a Python dataframe library as a dplyr user",
    "section": "",
    "text": "I‚Äôm a long time R user and lately I‚Äôve seen more and more signals that it‚Äôs worth investing into Python. I use it for NLP with spaCy and to build functions on AWS Lambda. Further, there are many more data API libraries and machine learning libraries for Python than for R.\nAdopting Python means making choices on which libraries to invest time into learning. Manipulating data frames is one of the most common data science activities, so choosing the right library for it is key.\nMichael Chow, developer of siuba, a Python port of dplyr on top of pandas wrote describes the situation well:\nThe higher-level libraries he mentions come with a problem : There‚Äôs no universal standard.\nIn a discussion of the polars library on Hacker News the user ‚Äúcivilized‚Äù put the dplyr user perspective more bluntly:\nI‚Äôm more willing to compromise though, so here‚Äôs a comparison of the strongest contenders."
  },
  {
    "objectID": "blog/2024-11-01_dplyr_candidate/index.html#the-contenders",
    "href": "blog/2024-11-01_dplyr_candidate/index.html#the-contenders",
    "title": "Data frame wars: Choosing a Python dataframe library as a dplyr user",
    "section": "The contenders",
    "text": "The contenders\nThe database-like ops benchmark on H2Oai is a helpful performance comparison.\nI‚Äôm considering these libraries:\n\nPandas: The most commonly used library and the one with the most tutorials and Stack Overflow answers available.\nsiuba: A port of dplyr to Python, built on top of pandas. Not in the benchmark. Performance probably similar to pandas or worse due to translation.\nPolars: The fastest library available. According to the benchmark, it runs 3-10x faster than Pandas.\nDuckdb: Use an in-memory OLAP database instead of a dataframe and write SQL. In R, this can also be queried via dbplyr.\nibis. Backend-agnostic wrapper for pandas and SQL engines.\n\nThere are more options. I excluded the others for these reasons:\n\nSlower than polars and not with a readability focus (dask, Arrow, Modin, pydatatable)\nRequires or is optmized for running on a remote server (Spark, ClickHouse and most other SQL databases).\nNot meant for OLAP (sqlite)\nNot in Python (DataFrames.jl)\nMeant for GPU (cuDF)"
  },
  {
    "objectID": "blog/2024-11-01_dplyr_candidate/index.html#github-stars-as-a-proxy-for-popularity",
    "href": "blog/2024-11-01_dplyr_candidate/index.html#github-stars-as-a-proxy-for-popularity",
    "title": "Data frame wars: Choosing a Python dataframe library as a dplyr user",
    "section": "Github stars as a proxy for popularity",
    "text": "Github stars as a proxy for popularity\nThe benchmark provides a comparison of performance, but another important factor is popularity and maturity. A more mature library has a more stable API, better test coverage and there is more help available online, such as on StackOverflow. One way to measure popularity is the number of stars that the package repository has on Github.\n\nlibrary(ggplot2)\nlibs &lt;- data.frame(\n    library = c(\"pandas\", \"siuba\", \"polars\", \"duckdb\", \"dplyr\", \"data.table\", \"pydatatable\", \"dtplyr\", \"tidytable\", \"ibis\"),\n    language = c(\"Python\", \"Python\", \"Python\", \"SQL\", \"R\", \"R\", \"Python\", \"R\", \"R\", \"Python\"),\n    stars = c(32100, 732, 3900, 4100, 3900, 2900, 1400, 542, 285, 1600)\n)\n\nggplot(libs, aes(x = reorder(library, -stars), y = stars, fill = language)) +\n    geom_col() +\n    labs(\n        title = \"Pandas is by far the most popular choice\",\n        subtitle = \"Comparison of Github stars\",\n        fill = \"Language\",\n        x = \"Library\",\n        y = \"Github stars\"\n    )\n\n\n\n\n\n\n\n\nGithub stars are not a perfect proxy. For instance, dplyr is more mature than its star count suggests. Comparing the completeness of the documentation and tutorials for dplyr and polars reveals that it‚Äôs a day and night difference.\nWith the quantitative comparison out of the way, here‚Äôs a qualitative comparison of the Python packages. I‚Äôm speaking of my personal opinion of these packages - not a general comparison. My reference is my current use of dplyr in R. When I need more performance, I use tidytable to get most of the speed of data.table with the grammar of dplyr and eager evaluation. Another alternative is dtplyr, which translates dplyr to data.table with lazy evaluation. I also use dbplyr, which translates dplyr to SQL.\nI‚Äôll compare the libraries by running a data transformation pipeline involving import from CSV, mutate, filter, sort, join, group by and summarize. I‚Äôll use the nycflights13 dataset, which is featured in Hadley Wickham‚Äôs R for Data Science."
  },
  {
    "objectID": "blog/2024-11-01_dplyr_candidate/index.html#dplyr-reference-in-r",
    "href": "blog/2024-11-01_dplyr_candidate/index.html#dplyr-reference-in-r",
    "title": "Data frame wars: Choosing a Python dataframe library as a dplyr user",
    "section": "dplyr: Reference in R",
    "text": "dplyr: Reference in R\nLet‚Äôs start with a reference implementation in dplyr. The dataset is available as a package, so I skip the CSV import.\n\nlibrary(dplyr, warn.conflicts = FALSE)\nlibrary(nycflights13)\nlibrary(reactable)\n\n# Take a look at the tables\nreactable(head(flights, 10))\n\n\n\n\nreactable(head(airlines, 10))\n\n\n\n\n\nThe flights tables has 336776 rows, one for each flight of an airplane. The airlines table has 16 rows, one for each airline mapping the full name of the company to a code.\nLet‚Äôs find the airline with the highest arrival delays in January 2013.\n\nflights |&gt;\n    filter(year == 2013, month == 1, !is.na(arr_delay)) |&gt;\n    mutate(arr_delay = replace(arr_delay, arr_delay &lt; 0, 0)) |&gt;\n    left_join(airlines, by = \"carrier\") |&gt;\n    group_by(airline = name) |&gt;\n    summarise(flights = n(), mean_delay = mean(arr_delay)) |&gt;\n    arrange(desc(mean_delay))\n\n# A tibble: 16 √ó 3\n   airline                     flights mean_delay\n   &lt;chr&gt;                         &lt;int&gt;      &lt;dbl&gt;\n 1 SkyWest Airlines Inc.             1     107   \n 2 Hawaiian Airlines Inc.           31      48.8 \n 3 ExpressJet Airlines Inc.       3964      29.6 \n 4 Frontier Airlines Inc.           59      23.9 \n 5 Mesa Airlines Inc.               39      20.4 \n 6 Endeavor Air Inc.              1480      19.3 \n 7 Alaska Airlines Inc.             62      17.6 \n 8 Envoy Air                      2203      14.3 \n 9 Southwest Airlines Co.          985      13.0 \n10 JetBlue Airways                4413      12.9 \n11 United Air Lines Inc.          4590      11.9 \n12 American Airlines Inc.         2724      11.0 \n13 AirTran Airways Corporation     324       9.95\n14 US Airways Inc.                1554       9.11\n15 Delta Air Lines Inc.           3655       8.07\n16 Virgin America                  314       3.17\n\n\nSome values in arr_delay are negative, indicating that the flight was faster than expected. I replaced these values with 0 because I don‚Äôt want them to cancel out delays of other flights. I joined to the airlines table to get the full names of the airlines.\nI export the flights and airlines tables to CSV to hand them over to Python.\n\n# Write to temporary files\nflights_path &lt;- tempfile(fileext = \".csv\")\nairlines_path &lt;- tempfile(fileext = \".csv\")\n\ndata.table::fwrite(flights, flights_path, row.names = FALSE)\ndata.table::fwrite(airlines, airlines_path, row.names = FALSE)\n\nTo access the file from Python, the path is handed over:\n\n\n#| eval: false\n# Hand over the path from R\nflights_path = r[\"flights_path\"]\nairlines_path = r[\"airlines_path\"]\n\nFor more details on how this works with the reticulate package, check this documentation."
  },
  {
    "objectID": "blog/2024-11-01_dplyr_candidate/index.html#pandas-most-popular",
    "href": "blog/2024-11-01_dplyr_candidate/index.html#pandas-most-popular",
    "title": "Data frame wars: Choosing a Python dataframe library as a dplyr user",
    "section": "Pandas: Most popular",
    "text": "Pandas: Most popular\nThe following sections follow a pattern: read in from CSV, then build a query.\n\nimport pandas as pd\n\n# Import from CSV\nflights_pd = pd.read_csv(flights_path)\nairlines_pd = pd.read_csv(airlines_path)\n\npandas.read_csv reads the header and conveniently infers the column types.\n\n(\n    flights_pd.query(\"year == 2013 & month == 1 & arr_delay.notnull()\")\n    .assign(arr_delay=flights_pd.arr_delay.clip(lower=0))\n    .merge(airlines_pd, how=\"left\", on=\"carrier\")\n    .rename(columns={\"name\": \"airline\"})\n    .groupby(\"airline\")\n    .agg(flights=(\"airline\", \"count\"), mean_delay=(\"arr_delay\", \"mean\"))\n    .sort_values(by=\"mean_delay\", ascending=False)\n)\n\n                             flights  mean_delay\nairline                                         \nSkyWest Airlines Inc.              1  107.000000\nHawaiian Airlines Inc.            31   48.774194\nExpressJet Airlines Inc.        3964   29.642785\nFrontier Airlines Inc.            59   23.881356\nMesa Airlines Inc.                39   20.410256\nEndeavor Air Inc.               1480   19.321622\nAlaska Airlines Inc.              62   17.645161\nEnvoy Air                       2203   14.303677\nSouthwest Airlines Co.           985   12.964467\nJetBlue Airways                 4413   12.919329\nUnited Air Lines Inc.           4590   11.851852\nAmerican Airlines Inc.          2724   10.953377\nAirTran Airways Corporation      324    9.953704\nUS Airways Inc.                 1554    9.111326\nDelta Air Lines Inc.            3655    8.070315\nVirgin America                   314    3.165605\n\n\nI chose to use the pipeline syntax from pandas - another option is to modify the dataset in place. That has a lower memory footprint, but can‚Äôt be run repeatedly for the same result, such as in interactive use in a notebook.\nHere, the query() function is slightly awkward with the long string argument. The groupby doesn‚Äôt allow renaming on the fly like dplyr, though I don‚Äôt consider that a real drawback. Perhaps it‚Äôs clearer to rename explicitly anyway.\nPandas has the widest API, offering hundreds of functions for every conceivable manipulation. The clip function used here is one such example. One difference to dplyr is that pandas uses its own methods .mean(), rather than using external ones such as base::mean(). That means using custom functions instead carries a performance penalty.\nAs we‚Äôll see later, pandas is the backend for siuba and ibis, which boil down to pandas code.\nOne difference to all other discussed solutions is that pandas uses a row index. Base R also has this with row names, but the tidyverse and tibbles have largely removed them from common use. I never missed row names. At the times I had to work with them in pandas they were more confusing than helpful. The documentation of polars puts it more bluntly:\n\nNo index. They are not needed. Not having them makes things easier. Convince me otherwise\n\nThat‚Äôs quite passive aggressive, but I do agree and wish pandas didn‚Äôt have it."
  },
  {
    "objectID": "blog/2024-11-01_dplyr_candidate/index.html#siuba-dplyr-in-python",
    "href": "blog/2024-11-01_dplyr_candidate/index.html#siuba-dplyr-in-python",
    "title": "Data frame wars: Choosing a Python dataframe library as a dplyr user",
    "section": "siuba: dplyr in Python",
    "text": "siuba: dplyr in Python\n\nimport siuba as si\n\n# Import from CSV\nflights_si = pd.read_csv(r[\"flights_path\"])\nairlines_si = pd.read_csv(r[\"airlines_path\"])\n\nAs siuba is just an alternative way of writing some pandas commands, we read the data just like in the pandas implementation.\n\n(\n    flights_si\n    &gt;&gt; si.filter(si._.year == 2013, si._.month == 1, si._.arr_delay.notnull())\n    &gt;&gt; si.mutate(arr_delay=si._.arr_delay.clip(lower=0))\n    &gt;&gt; si.left_join(si._, airlines_si, on=\"carrier\")\n    &gt;&gt; si.rename(airline=si._.name)\n    &gt;&gt; si.group_by(si._.airline)\n    &gt;&gt; si.summarize(flights=si._.airline.count(), mean_delay=si._.arr_delay.mean())\n    &gt;&gt; si.arrange(-si._.mean_delay)\n)\n\nI found siuba the easiest to work with. Once I understood the _ placeholder for a table of data, I could write it almost as fast as dplyr. Out of all the ways to refer to a column in a data frame, I found it to be the most convenient, because it doesn‚Äôt require me to spell out the name of the data frame over and over. While not as elegant as dplyr‚Äôs tidy evaluation (discussed at the end of the article), it avoids the ambivalence in dplyr where it can be unclear whether a name refers to a column or an outside object.\nIt‚Äôs always possible to drop into pandas, such as for the aggregation functions which use the mean() and count() methods of the pandas series. The &gt;&gt; is an easy replacement for the %&gt;% magrittr pipe or |&gt; base pipe in R.\nThe author advertises siuba like this (from the docs):\n\nSiuba is a library for quick, scrappy data analysis in Python. It is a port of dplyr, tidyr, and other R Tidyverse libraries.\n\nA way for dplyr users to quickly hack away at data analysis in Python, but not meant for unsupervised production use."
  },
  {
    "objectID": "blog/2024-11-01_dplyr_candidate/index.html#polars-fastest",
    "href": "blog/2024-11-01_dplyr_candidate/index.html#polars-fastest",
    "title": "Data frame wars: Choosing a Python dataframe library as a dplyr user",
    "section": "Polars: Fastest",
    "text": "Polars: Fastest\nPolars is written in Rust and also offers a Python API. It comes in two flavors: eager and lazy. Lazy evaluation is similar to how dbplyr and dtplyr work: until asked, nothing is evaluated. This enables performance gains by reordering the commands being executed. But it‚Äôs a little less convenient for interactive analysis. I‚Äôll use the eager API here.\n\nimport polars as pl\n\n# Import from CSV\nflights_pl = pl.read_csv(flights_path)\nairlines_pl = pl.read_csv(airlines_path)\n\n\n(\n    flights_pl.filter((pl.col(\"year\") == 2013) & (pl.col(\"month\") == 1))\n    .drop_nulls(\"arr_delay\")\n    .join(airlines_pl, on=\"carrier\", how=\"left\")\n    .with_columns(\n        [\n            pl.when(pl.col(\"arr_delay\") &gt; 0)\n            .then(pl.col(\"arr_delay\"))\n            .otherwise(0)\n            .alias(\"arr_delay\"),\n            pl.col(\"name\").alias(\"airline\"),\n        ]\n    )\n    .groupby(\"airline\")\n    .agg(\n        [pl.count(\"airline\").alias(\"flights\"), pl.mean(\"arr_delay\").alias(\"mean_delay\")]\n    )\n    .sort(\"mean_delay\", descending=True)\n)\n\nThe API is leaner than pandas, requiring to memorize fewer functions and patterns. Though this can also be seen as less feature-complete. Pandas, for example has a dedicated clip function.\nThere isn‚Äôt nearly as much help available for problems with polars as for with pandas. While the documentation is good, it can‚Äôt answer every question and lots of trial and error is needed.\nA comparison of polars and pandas is available in the polars documentation."
  },
  {
    "objectID": "blog/2024-11-01_dplyr_candidate/index.html#duckdb-highly-compatible-and-easy-for-sql-users",
    "href": "blog/2024-11-01_dplyr_candidate/index.html#duckdb-highly-compatible-and-easy-for-sql-users",
    "title": "Data frame wars: Choosing a Python dataframe library as a dplyr user",
    "section": "DuckDB: Highly compatible and easy for SQL users",
    "text": "DuckDB: Highly compatible and easy for SQL users\n\nimport duckdb\n\ncon_duckdb = duckdb.connect(database=\":memory:\")\n\n# Import from CSV\ncon_duckdb.execute(\n    \"CREATE TABLE 'flights' AS \"\n    f\"SELECT * FROM read_csv_auto('{flights_path}', header = True);\"\n    \"CREATE TABLE 'airlines' AS \"\n    f\"SELECT * FROM read_csv_auto('{airlines_path}', header = True);\"\n)\n\n&lt;duckdb.duckdb.DuckDBPyConnection object at 0x0000014F23081730&gt;\n\n\nDuckDB‚Äôs read_csv_auto() works just like the csv readers in Python.\n\ncon_duckdb.execute(\n    \"WITH flights_clipped AS ( \"\n    \"SELECT carrier, CASE WHEN arr_delay &gt; 0 THEN arr_delay ELSE 0 END AS arr_delay \"\n    \"FROM flights \"\n    \"WHERE year = 2013 AND month = 1 AND arr_delay IS NOT NULL\"\n    \")\"\n    \"SELECT name AS airline, COUNT(*) AS flights, AVG(arr_delay) AS mean_delay \"\n    \"FROM flights_clipped \"\n    \"LEFT JOIN airlines ON flights_clipped.carrier = airlines.carrier \"\n    \"GROUP BY name \"\n    \"ORDER BY mean_delay DESC \"\n).fetchdf()\n\n                        airline  flights  mean_delay\n0         SkyWest Airlines Inc.        1  107.000000\n1        Hawaiian Airlines Inc.       31   48.774194\n2      ExpressJet Airlines Inc.     3964   29.642785\n3        Frontier Airlines Inc.       59   23.881356\n4            Mesa Airlines Inc.       39   20.410256\n5             Endeavor Air Inc.     1480   19.321622\n6          Alaska Airlines Inc.       62   17.645161\n7                     Envoy Air     2203   14.303677\n8        Southwest Airlines Co.      985   12.964467\n9               JetBlue Airways     4413   12.919329\n10        United Air Lines Inc.     4590   11.851852\n11       American Airlines Inc.     2724   10.953377\n12  AirTran Airways Corporation      324    9.953704\n13              US Airways Inc.     1554    9.111326\n14         Delta Air Lines Inc.     3655    8.070315\n15               Virgin America      314    3.165605\n\n\nThe performance is closer to polars than to pandas. A big plus is the ability to handle larger than memory data.\nDuckDB can also operate directly on a pandas dataframe. The SQL code is portable to R, C, C++, Java and other programming languages the duckdb has APIs. It‚Äôs also portable when the logic is taken to a DB like Postgres, or Clickhouse, or is ported to an ETL framework like DBT.\nThis stands in contrast to polars and pandas code, which has to be rewritten from scratch. It also means that the skill gained in manipulating SQL translates well to other situations. SQL has been around for more than 50 years - learning SQL is future-proofing a career.\nWhile these are big plusses, duckdb isn‚Äôt so convenient for interactive data exploration. SQL isn‚Äôt as composeable. Composing SQL queries requires many common table expressions (CTEs, WITH x AS (SELECT ...)). Reusing them for other queries is not as easy as with Python. SQL is typically less expressive than Python. It lacks shorthands and it‚Äôs awkward when there are many columns. It‚Äôs also harder to write custom functions in SQL than in R or Python. This is the motivation for using libraries like pandas and dplyr. But SQL can actually do a surprising amount of things, as database expert Haki Benita explained in a detailed article.\nOr in short, from the documentation of ibis:\n\nSQL is widely used and very convenient when writing simple queries. But as the complexity of operations grow, SQL can become very difficult to deal with.\n\nThen, there‚Äôs the issue of how to actually write the SQL code. Writing strings rather than actual Python is awkward and many editors don‚Äôt provide syntax highlighting within the strings (Jetbrains editors like PyCharm and DataSpell do). The other option is writing .sql that have placeholders for parameters. That‚Äôs cleaner and allows using a linter, but is inconvenient for interactive use.\nSQL is inherently lazily executed, because the query planner needs to take the whole query into account before starting computation. This enables performance gains. For interactive use, lazy evaluation is less convenient, because one can‚Äôt see the intermediate results at each step. Speed of iteration is critical: the faster one can iterate, the more hypotheses about the data can be tested.\nThere is a programmatic way to construct queries for duckdb, designed to provide a dbplyr alternative in Python. Unfortunately its documentation is sparse.\nUsing duckdb without pandas doesn‚Äôt seem feasible for exploratory data analysis, because graphing packages like seaborn and plotly expect a pandas data frame or similar as an input."
  },
  {
    "objectID": "blog/2024-11-01_dplyr_candidate/index.html#ibis-lingua-franca-in-python",
    "href": "blog/2024-11-01_dplyr_candidate/index.html#ibis-lingua-franca-in-python",
    "title": "Data frame wars: Choosing a Python dataframe library as a dplyr user",
    "section": "ibis: Lingua franca in Python",
    "text": "ibis: Lingua franca in Python\nThe goal of ibis is to provide a universal language for working with data frames in Python, regardless of the backend that is used. It‚Äôs tagline is: Write your analytics code once, run in everywhere. This is similar to how dplyr can use SQL as a backend with dbplyr and data.table with dtplyr.\nAmong others, Ibis supports pandas, PostgreSQL and SQLite as backends. Unfortunately duckdb is not an available backend, because the authors of duckdb have decided against building on ibis.\nThe ibis project aims to bridge the gap between the needs of interactive data analysis and the capabilities of SQL, which I have detailed in the previous section on duckdb.\n\n\n\n\n\n\nNote\n\n\n\nUPDATE October 2023\n\nDuckdb is now a supported backend (along with many more). So performance is going to be very similar to duckdb.\nDirectly load/save data\njoin(), clip(), and case() are well-supported\nIbis is much more popular and now very actively maintained. There are more examples, better documentation, and community. Still definitely less than pandas, but perhaps comparable to polars.\n\nThanks to NickCrews for providing this update, including the following code example.\n\n\nFor the test drive, I‚Äôll use the duckdb backend, meaning that the ibis code is translated to duckdb operations, similar to how siuba is translated to pandas. This gives ibis the blazing speed of duckdb.\n\nimport ibis\nfrom ibis import _\n\nflights_ib_csv = pd.read_csv(flights_path)\nairlines_ib_csv = pd.read_csv(airlines_path)\n\nibis.options.interactive = True\n\nflights_ib = ibis.read_csv(flights_path)\nairlines_ib = ibis.read_csv(airlines_path)\nflights_ib\n\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îê\n‚îÇ year  ‚îÇ month ‚îÇ day   ‚îÇ dep_time ‚îÇ sched_dep_time ‚îÇ dep_delay ‚îÇ arr_time ‚îÇ  ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚î§\n‚îÇ int64 ‚îÇ int64 ‚îÇ int64 ‚îÇ int64    ‚îÇ int64          ‚îÇ int64     ‚îÇ int64    ‚îÇ  ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚î§\n‚îÇ  2013 ‚îÇ     1 ‚îÇ     1 ‚îÇ      517 ‚îÇ            515 ‚îÇ         2 ‚îÇ      830 ‚îÇ  ‚îÇ\n‚îÇ  2013 ‚îÇ     1 ‚îÇ     1 ‚îÇ      533 ‚îÇ            529 ‚îÇ         4 ‚îÇ      850 ‚îÇ  ‚îÇ\n‚îÇ  2013 ‚îÇ     1 ‚îÇ     1 ‚îÇ      542 ‚îÇ            540 ‚îÇ         2 ‚îÇ      923 ‚îÇ  ‚îÇ\n‚îÇ  2013 ‚îÇ     1 ‚îÇ     1 ‚îÇ      544 ‚îÇ            545 ‚îÇ        -1 ‚îÇ     1004 ‚îÇ  ‚îÇ\n‚îÇ  2013 ‚îÇ     1 ‚îÇ     1 ‚îÇ      554 ‚îÇ            600 ‚îÇ        -6 ‚îÇ      812 ‚îÇ  ‚îÇ\n‚îÇ  2013 ‚îÇ     1 ‚îÇ     1 ‚îÇ      554 ‚îÇ            558 ‚îÇ        -4 ‚îÇ      740 ‚îÇ  ‚îÇ\n‚îÇ  2013 ‚îÇ     1 ‚îÇ     1 ‚îÇ      555 ‚îÇ            600 ‚îÇ        -5 ‚îÇ      913 ‚îÇ  ‚îÇ\n‚îÇ  2013 ‚îÇ     1 ‚îÇ     1 ‚îÇ      557 ‚îÇ            600 ‚îÇ        -3 ‚îÇ      709 ‚îÇ  ‚îÇ\n‚îÇ  2013 ‚îÇ     1 ‚îÇ     1 ‚îÇ      557 ‚îÇ            600 ‚îÇ        -3 ‚îÇ      838 ‚îÇ  ‚îÇ\n‚îÇ  2013 ‚îÇ     1 ‚îÇ     1 ‚îÇ      558 ‚îÇ            600 ‚îÇ        -2 ‚îÇ      753 ‚îÇ  ‚îÇ\n‚îÇ     ‚Ä¶ ‚îÇ     ‚Ä¶ ‚îÇ     ‚Ä¶ ‚îÇ        ‚Ä¶ ‚îÇ              ‚Ä¶ ‚îÇ         ‚Ä¶ ‚îÇ        ‚Ä¶ ‚îÇ  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îò\n\n\nNon-interactive ibis means that queries are evaluated lazily.\n\n(\n    flights_ib.filter(\n        [\n            _.year == 2013,\n            _.month == 1,\n            _.arr_delay.notnull(),\n        ]\n    )\n    .join(airlines_ib, \"carrier\", how=\"left\")\n    .select(arr_delay=_.arr_delay.clip(lower=0), airline=_.name)\n    .group_by(\"airline\")\n    .agg(flights=_.count(), mean_delay=_.arr_delay.mean())\n    .order_by(_.mean_delay.desc())\n)\n\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ airline                  ‚îÇ flights ‚îÇ mean_delay ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ string                   ‚îÇ int64   ‚îÇ float64    ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ SkyWest Airlines Inc.    ‚îÇ       1 ‚îÇ 107.000000 ‚îÇ\n‚îÇ Hawaiian Airlines Inc.   ‚îÇ      31 ‚îÇ  48.774194 ‚îÇ\n‚îÇ ExpressJet Airlines Inc. ‚îÇ    3964 ‚îÇ  29.642785 ‚îÇ\n‚îÇ Frontier Airlines Inc.   ‚îÇ      59 ‚îÇ  23.881356 ‚îÇ\n‚îÇ Mesa Airlines Inc.       ‚îÇ      39 ‚îÇ  20.410256 ‚îÇ\n‚îÇ Endeavor Air Inc.        ‚îÇ    1480 ‚îÇ  19.321622 ‚îÇ\n‚îÇ Alaska Airlines Inc.     ‚îÇ      62 ‚îÇ  17.645161 ‚îÇ\n‚îÇ Envoy Air                ‚îÇ    2203 ‚îÇ  14.303677 ‚îÇ\n‚îÇ Southwest Airlines Co.   ‚îÇ     985 ‚îÇ  12.964467 ‚îÇ\n‚îÇ JetBlue Airways          ‚îÇ    4413 ‚îÇ  12.919329 ‚îÇ\n‚îÇ ‚Ä¶                        ‚îÇ       ‚Ä¶ ‚îÇ          ‚Ä¶ ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\nThe syntax looks quite similar to dplyr and the versatility of interchangeable backends is remarkable. In the first version of this article, ibis was lacking in documentation and had some rough edges in the API, but these were improved in the meantime."
  },
  {
    "objectID": "blog/2024-11-01_dplyr_candidate/index.html#conclusion",
    "href": "blog/2024-11-01_dplyr_candidate/index.html#conclusion",
    "title": "Data frame wars: Choosing a Python dataframe library as a dplyr user",
    "section": "Conclusion",
    "text": "Conclusion\nIt‚Äôs not a clear-cut choice. None of the options offer a syntax that is as convenient for interactive analysis as dplyr. siuba is the closest to it, but dplyr still has an edge with tidy evaluation, letting users refer to columns in a data frame by their names (colname) directly, without any wrappers. But I‚Äôve also seen it be confusing for newbies to R that mix it up with base R‚Äôs syntax. It‚Äôs also harder to program with, where it‚Äôs necessary to use operators like { } and :=.\nMy appreciation for dplyr (and the closely associated tidyr) grew during this research. Not only is it a widely accepted standard like pandas, it can also be used as a translation layer for backends like SQL databases (including duckdb), data.table, and Spark. All while having the most elegant and flexible syntax available.\nPersonally, I‚Äôll primarily leverage SQL and a OLAP database (such as Clickhouse or Snowflake) running on a server to do the heavy lifting. For steps that are better done locally, I‚Äôll use pandas for maximum compatibility. I find the use of an index inconvenient, but there‚Äôs so much online help available on StackOverflow. Github Copilot also deserves a mention for making it easier to pick up. Other use cases can be very different, so I don‚Äôt mean to say that my way is the best. For instance, if the data is not already on a server, fast local processing with polars may be best.\nMost data science work happens in a team. Choosing a library that all team members are familiar with is critical for collaboration. That is typically SQL, pandas or dplyr. The performance gains from using a less common library like polars have to be weighed against the effort spent learning the syntax as well as the increased likelihood of bugs, when beginners write in a new syntax.\nRelated articles:\n\nPolars: the fastest DataFrame library you‚Äôve never heard of\nWhat would it take to recreate dplyr in python?\nPandas has a hard job (and does it well)\ndplyr in Python? First impressions of the siuba module\nAn Overview of Python‚Äôs Datatable package\nDiscussion of DuckDB on Hacker News\nDiscussion of Polars on Hacker News\nPractical SQL for Data Analysis"
  }
]